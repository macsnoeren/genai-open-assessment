# Het gebruik van generatieve AI voor geautomatiseerde beoordeling van open kennisvragen in het hoger onderwijs
**Maurice Snoeren, 28-01-2026**

---

## Abstract
De opkomst van generatieve artificiële intelligentie (genAI) heeft geleid tot fundamentele vragen over toetsing en examinering in het hoger onderwijs. Waar genAI vaak wordt gezien als een bedreiging voor traditionele toetsvormen, biedt dezelfde technologie ook kansen om juist de toetsing van diepgaande kennis te versterken.  

In dit artikel wordt een toetsconcept beschreven waarbij docenten genAI inzetten om open kennisvragen automatisch te beoordelen op basis van expliciet gedefinieerde beoordelingscriteria en strikt ontworpen prompts.  

De centrale hypothese is dat genAI-gebaseerde beoordeling van open vragen een valide, schaalbare en controleerbare methode kan zijn om kennis van studenten te toetsen, mits het prompt-ontwerp voldoende beperkingen oplegt aan het modelgedrag.  

Op basis van een literatuurstudie en praktijkinzichten wordt aangetoond dat prompt-ontwerp een cruciale didactische en technische factor vormt in genAI-toetsing. Het artikel sluit af met concrete richtlijnen voor docenten.

**Trefwoorden:** generatieve AI, toetsing, open vragen, prompt-ontwerp, automatische beoordeling

---

## 1. Inleiding
Toetsing vervult een centrale rol in het hoger onderwijs, zowel als meetinstrument voor leerresultaten als sturingsmechanisme voor leren (Biggs & Tang, 2011). Open kennisvragen worden algemeen beschouwd als valide instrumenten om conceptueel begrip en samenhangende kennis te toetsen, maar hun toepassing wordt in de praktijk beperkt door de hoge beoordelingslast voor docenten.  

Met de opkomst van generatieve AI, en in het bijzonder grote taalmodellen (LLM’s), ontstaat de mogelijkheid om deze beoordelingslast gedeeltelijk te automatiseren. Tegelijkertijd blijkt in de praktijk dat ongecontroleerd gebruik van genAI leidt tot inconsistente, moeilijk verwerkbare en pedagogisch ongewenste output.  

Dit artikel betoogt dat niet het model, maar het promptontwerp bepalend is voor de betrouwbaarheid van genAI-gebaseerde kennistoetsing.

---

## 2. Probleemstelling en hypothese
Hoewel genAI technisch in staat is om open antwoorden te analyseren, blijkt in de praktijk dat modellen vaak extra uitleg geven, eigen beoordelingscriteria introduceren of afwijken van afgesproken beoordelingsschalen. Dit vormt een risico voor toetsvaliditeit, transparantie en navolgbaarheid.  

**Centrale hypothese:**  
> Generatieve AI kan open kennisvragen valide, consistent en schaalbaar beoordelen, mits docenten expliciete beoordelingscriteria combineren met strikt gedefinieerde prompts die het modelgedrag beperken.

---

## 3. Conceptueel model voor genAI-gebaseerde kennistoetsing
In het voorgestelde model ontwikkelt de docent een toetsapplicatie waarin genAI fungeert als uitvoerend beoordelingsmechanisme. De docent blijft verantwoordelijk voor:  

- het formuleren van leerdoelen  
- het ontwerpen van open kennisvragen  
- het definiëren van beoordelingscriteria  
- het ontwerpen en beheren van prompts  

GenAI voert uitsluitend uit wat expliciet is gedefinieerd. Alle studentantwoorden, prompts en AI-output worden opgeslagen, zodat herbeoordeling en auditing mogelijk blijven.

---

## 4. Literatuurstudie

### 4.1 Automatische beoordeling van open antwoorden
Recente studies tonen aan dat LLM’s in staat zijn om open antwoorden te beoordelen met een betrouwbaarheid die in veel gevallen vergelijkbaar is met menselijke beoordelaars, mits gebruik wordt gemaakt van expliciete rubrics (Zhai et al., 2025). Zonder dergelijke rubrics neemt de variatie in beoordeling significant toe.

### 4.2 Rubric- en prompt-gebaseerde beoordeling
Onderzoek naar rubric-aligned grading (Kumar et al., 2024) laat zien dat AI-modellen beter presteren wanneer zij strikt binnen vooraf gedefinieerde beoordelingsdimensies opereren. Recente praktijkstudies benadrukken dat prompt-ontwerp hierbij een even belangrijke rol speelt als de rubric zelf.

### 4.3 Validiteit, transparantie en AI
Onderwijskundige literatuur benadrukt dat toetsvaliditeit afhankelijk is van consistentie, uitlegbaarheid en controleerbaarheid (Biggs & Tang, 2011). Nederlandse richtlijnen (SURF Communities, 2024) stellen dat AI-gebruik bij toetsing alleen verantwoord is wanneer menseli
